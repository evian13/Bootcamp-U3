{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U3L3.4\n",
    "## Challenge -\n",
    "Engineer your features, then create three models. Each model will be run on a training set and a test-set (or multiple test-sets, if you take a folds approach). The models should be:\n",
    "1. Vanilla logistic regression\n",
    "2. Ridge logistic regression\n",
    "3. Lasso logistic regression\n",
    "\n",
    " for classification\n",
    "\n",
    "If you're stuck on how to begin combining your two new modeling skills, here's a hint: the SKlearn LogisticRegression method has a \"penalty\" argument that takes either 'l1' or 'l2' as a value.\n",
    "\n",
    "In your report, evaluate all three models and decide on your best. Be clear about the decisions you made that led to these models (feature selection, regularization parameter selection, model evaluation criteria) and why you think that particular model is the best of the three. Also reflect on the strengths and limitations of regression as a modeling approach. Were there things you couldn't do but you wish you could have done?\n",
    "\n",
    "### We would like to predict if the city will be classified as a murder one or safe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Display preferences.\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "# Suppress annoying harmless error.\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.mlab import PCA as mlabPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Population</th>\n",
       "      <th>Violent\n",
       "crime</th>\n",
       "      <th>Murder and\n",
       "nonnegligent\n",
       "manslaughter</th>\n",
       "      <th>Rape\n",
       "(revised\n",
       "definition)1</th>\n",
       "      <th>Rape\n",
       "(legacy\n",
       "definition)2</th>\n",
       "      <th>Robbery</th>\n",
       "      <th>Aggravated\n",
       "assault</th>\n",
       "      <th>Property\n",
       "crime</th>\n",
       "      <th>Burglary</th>\n",
       "      <th>Larceny-\n",
       "theft</th>\n",
       "      <th>Motor\n",
       "vehicle\n",
       "theft</th>\n",
       "      <th>Arson3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Woodbury Town</td>\n",
       "      <td>10,685</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>541</td>\n",
       "      <td>9</td>\n",
       "      <td>529</td>\n",
       "      <td>3</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>Woodridge Village</td>\n",
       "      <td>829</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>Woodstock Town</td>\n",
       "      <td>5,931</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>Yonkers</td>\n",
       "      <td>199,134</td>\n",
       "      <td>1,036</td>\n",
       "      <td>6</td>\n",
       "      <td>nan</td>\n",
       "      <td>25</td>\n",
       "      <td>390</td>\n",
       "      <td>615</td>\n",
       "      <td>2,368</td>\n",
       "      <td>470</td>\n",
       "      <td>1,662</td>\n",
       "      <td>236</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Yorktown Town</td>\n",
       "      <td>36,643</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>334</td>\n",
       "      <td>45</td>\n",
       "      <td>287</td>\n",
       "      <td>2</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  City Population Violent\\ncrime  \\\n",
       "343      Woodbury Town     10,685              3   \n",
       "344  Woodridge Village        829              7   \n",
       "345     Woodstock Town      5,931              2   \n",
       "346            Yonkers    199,134          1,036   \n",
       "347      Yorktown Town     36,643             15   \n",
       "\n",
       "     Murder and\\nnonnegligent\\nmanslaughter  Rape\\n(revised\\ndefinition)1  \\\n",
       "343                                       0                           nan   \n",
       "344                                       0                           nan   \n",
       "345                                       0                           nan   \n",
       "346                                       6                           nan   \n",
       "347                                       0                           nan   \n",
       "\n",
       "    Rape\\n(legacy\\ndefinition)2 Robbery Aggravated\\nassault Property\\ncrime  \\\n",
       "343                           0       2                   1             541   \n",
       "344                           0       0                   7              17   \n",
       "345                           0       0                   2              58   \n",
       "346                          25     390                 615           2,368   \n",
       "347                           0       2                  13             334   \n",
       "\n",
       "    Burglary Larceny-\\ntheft Motor\\nvehicle\\ntheft  Arson3  \n",
       "343        9             529                     3     nan  \n",
       "344        8               9                     0   0.000  \n",
       "345       13              45                     0     nan  \n",
       "346      470           1,662                   236  10.000  \n",
       "347       45             287                     2     nan  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = 'https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/master/New_York_offenses/NEW_YORK-Offenses_Known_to_Law_Enforcement_by_City_2013%20-%2013tbl8ny.csv'\n",
    "\n",
    "indices_to_skip = np.array([0,1,2,353,354,355])\n",
    "\n",
    "df = pd.read_csv(link,skiprows=indices_to_skip , header=1)\n",
    "\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(348, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                                       object\n",
       "Population                                 object\n",
       "Violent\\ncrime                             object\n",
       "Murder and\\nnonnegligent\\nmanslaughter      int64\n",
       "Rape\\n(revised\\ndefinition)1              float64\n",
       "Rape\\n(legacy\\ndefinition)2                object\n",
       "Robbery                                    object\n",
       "Aggravated\\nassault                        object\n",
       "Property\\ncrime                            object\n",
       "Burglary                                   object\n",
       "Larceny-\\ntheft                            object\n",
       "Motor\\nvehicle\\ntheft                      object\n",
       "Arson3                                    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Murder'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not working:\n",
    "new_cols = ['Murder','Rubberry']\n",
    "def insert_cols(df):\n",
    "    for i in range(len(new_cols)):\n",
    "        #df[new_cols[i]]==np.nan\n",
    "        return new_cols[i]\n",
    "    \n",
    "insert_cols(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace ',' before converting to numeric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.drop(['City','Murder and\\nnonnegligent\\nmanslaughter','Rape\\n(revised\\ndefinition)1'])\n",
    "\n",
    "# Replace ',' before converting to numeric:\n",
    "df[cols]=df[cols].replace(',*','',regex=True)\n",
    "\n",
    "# Convert to numeric\n",
    "df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 348 entries, 0 to 347\n",
      "Data columns (total 13 columns):\n",
      "City                                    348 non-null object\n",
      "Population                              348 non-null int64\n",
      "Violent\n",
      "crime                           348 non-null int64\n",
      "Murder and\n",
      "nonnegligent\n",
      "manslaughter    348 non-null int64\n",
      "Rape\n",
      "(revised\n",
      "definition)1              0 non-null float64\n",
      "Rape\n",
      "(legacy\n",
      "definition)2               348 non-null int64\n",
      "Robbery                                 348 non-null int64\n",
      "Aggravated\n",
      "assault                      348 non-null int64\n",
      "Property\n",
      "crime                          348 non-null int64\n",
      "Burglary                                348 non-null int64\n",
      "Larceny-\n",
      "theft                          348 non-null int64\n",
      "Motor\n",
      "vehicle\n",
      "theft                     348 non-null int64\n",
      "Arson3                                  187 non-null float64\n",
      "dtypes: float64(2), int64(10), object(1)\n",
      "memory usage: 35.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Population</th>\n",
       "      <th>Violent\n",
       "crime</th>\n",
       "      <th>Murder and\n",
       "nonnegligent\n",
       "manslaughter</th>\n",
       "      <th>Rape\n",
       "(revised\n",
       "definition)1</th>\n",
       "      <th>Rape\n",
       "(legacy\n",
       "definition)2</th>\n",
       "      <th>Robbery</th>\n",
       "      <th>Aggravated\n",
       "assault</th>\n",
       "      <th>Property\n",
       "crime</th>\n",
       "      <th>Burglary</th>\n",
       "      <th>Larceny-\n",
       "theft</th>\n",
       "      <th>Motor\n",
       "vehicle\n",
       "theft</th>\n",
       "      <th>Arson3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>348.000</td>\n",
       "      <td>348.000</td>\n",
       "      <td>348.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>348.000</td>\n",
       "      <td>348.000</td>\n",
       "      <td>348.000</td>\n",
       "      <td>348.000</td>\n",
       "      <td>348.000</td>\n",
       "      <td>348.000</td>\n",
       "      <td>348.000</td>\n",
       "      <td>187.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40037.632</td>\n",
       "      <td>201.595</td>\n",
       "      <td>1.566</td>\n",
       "      <td>nan</td>\n",
       "      <td>5.865</td>\n",
       "      <td>72.902</td>\n",
       "      <td>121.261</td>\n",
       "      <td>792.606</td>\n",
       "      <td>119.684</td>\n",
       "      <td>637.017</td>\n",
       "      <td>35.905</td>\n",
       "      <td>1.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>450037.368</td>\n",
       "      <td>2815.269</td>\n",
       "      <td>18.304</td>\n",
       "      <td>nan</td>\n",
       "      <td>60.425</td>\n",
       "      <td>1031.033</td>\n",
       "      <td>1706.132</td>\n",
       "      <td>7659.725</td>\n",
       "      <td>924.949</td>\n",
       "      <td>6346.054</td>\n",
       "      <td>403.424</td>\n",
       "      <td>10.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>526.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3003.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>40.500</td>\n",
       "      <td>6.000</td>\n",
       "      <td>31.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7233.500</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>112.500</td>\n",
       "      <td>17.500</td>\n",
       "      <td>94.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18427.500</td>\n",
       "      <td>22.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>2.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>341.000</td>\n",
       "      <td>51.250</td>\n",
       "      <td>287.250</td>\n",
       "      <td>7.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8396126.000</td>\n",
       "      <td>52384.000</td>\n",
       "      <td>335.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>1112.000</td>\n",
       "      <td>19170.000</td>\n",
       "      <td>31767.000</td>\n",
       "      <td>141971.000</td>\n",
       "      <td>16606.000</td>\n",
       "      <td>117931.000</td>\n",
       "      <td>7434.000</td>\n",
       "      <td>132.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Population  Violent\\ncrime  Murder and\\nnonnegligent\\nmanslaughter  \\\n",
       "count     348.000         348.000                                 348.000   \n",
       "mean    40037.632         201.595                                   1.566   \n",
       "std    450037.368        2815.269                                  18.304   \n",
       "min       526.000           0.000                                   0.000   \n",
       "25%      3003.000           2.000                                   0.000   \n",
       "50%      7233.500           6.000                                   0.000   \n",
       "75%     18427.500          22.000                                   0.000   \n",
       "max   8396126.000       52384.000                                 335.000   \n",
       "\n",
       "       Rape\\n(revised\\ndefinition)1  Rape\\n(legacy\\ndefinition)2   Robbery  \\\n",
       "count                         0.000                      348.000   348.000   \n",
       "mean                            nan                        5.865    72.902   \n",
       "std                             nan                       60.425  1031.033   \n",
       "min                             nan                        0.000     0.000   \n",
       "25%                             nan                        0.000     0.000   \n",
       "50%                             nan                        0.000     1.000   \n",
       "75%                             nan                        2.000     5.000   \n",
       "max                             nan                     1112.000 19170.000   \n",
       "\n",
       "       Aggravated\\nassault  Property\\ncrime  Burglary  Larceny-\\ntheft  \\\n",
       "count              348.000          348.000   348.000          348.000   \n",
       "mean               121.261          792.606   119.684          637.017   \n",
       "std               1706.132         7659.725   924.949         6346.054   \n",
       "min                  0.000            0.000     0.000            0.000   \n",
       "25%                  1.000           40.500     6.000           31.000   \n",
       "50%                  4.000          112.500    17.500           94.000   \n",
       "75%                 14.000          341.000    51.250          287.250   \n",
       "max              31767.000       141971.000 16606.000       117931.000   \n",
       "\n",
       "       Motor\\nvehicle\\ntheft  Arson3  \n",
       "count                348.000 187.000  \n",
       "mean                  35.905   1.872  \n",
       "std                  403.424  10.693  \n",
       "min                    0.000   0.000  \n",
       "25%                    0.000   0.000  \n",
       "50%                    2.000   0.000  \n",
       "75%                    7.000   1.000  \n",
       "max                 7434.000 132.000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >>> std in `Population` is huge, this is an outlier that kills the analysis!\n",
    "\n",
    "Drop values in \"Population\" that are outliers (more than 3 stdev from the mean):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = df[\"Population\"].quantile(0.99)\n",
    "df2=df[df[\"Population\"] < q].sort_values('Population', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Population</th>\n",
       "      <th>Violent\n",
       "crime</th>\n",
       "      <th>Murder and\n",
       "nonnegligent\n",
       "manslaughter</th>\n",
       "      <th>Rape\n",
       "(revised\n",
       "definition)1</th>\n",
       "      <th>Rape\n",
       "(legacy\n",
       "definition)2</th>\n",
       "      <th>Robbery</th>\n",
       "      <th>Aggravated\n",
       "assault</th>\n",
       "      <th>Property\n",
       "crime</th>\n",
       "      <th>Burglary</th>\n",
       "      <th>Larceny-\n",
       "theft</th>\n",
       "      <th>Motor\n",
       "vehicle\n",
       "theft</th>\n",
       "      <th>Arson3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>344.000</td>\n",
       "      <td>344.000</td>\n",
       "      <td>344.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>344.000</td>\n",
       "      <td>344.000</td>\n",
       "      <td>344.000</td>\n",
       "      <td>344.000</td>\n",
       "      <td>344.000</td>\n",
       "      <td>344.000</td>\n",
       "      <td>344.000</td>\n",
       "      <td>185.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14152.573</td>\n",
       "      <td>33.078</td>\n",
       "      <td>0.334</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.939</td>\n",
       "      <td>10.378</td>\n",
       "      <td>20.427</td>\n",
       "      <td>316.703</td>\n",
       "      <td>53.863</td>\n",
       "      <td>253.366</td>\n",
       "      <td>9.474</td>\n",
       "      <td>1.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18876.821</td>\n",
       "      <td>105.876</td>\n",
       "      <td>1.560</td>\n",
       "      <td>nan</td>\n",
       "      <td>5.662</td>\n",
       "      <td>36.304</td>\n",
       "      <td>64.049</td>\n",
       "      <td>602.881</td>\n",
       "      <td>134.721</td>\n",
       "      <td>454.847</td>\n",
       "      <td>28.851</td>\n",
       "      <td>4.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>526.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2983.250</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>39.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>31.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7106.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>111.500</td>\n",
       "      <td>17.000</td>\n",
       "      <td>93.500</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17889.250</td>\n",
       "      <td>21.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>2.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>13.250</td>\n",
       "      <td>334.750</td>\n",
       "      <td>50.000</td>\n",
       "      <td>275.500</td>\n",
       "      <td>7.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>143834.000</td>\n",
       "      <td>1192.000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>75.000</td>\n",
       "      <td>400.000</td>\n",
       "      <td>696.000</td>\n",
       "      <td>6473.000</td>\n",
       "      <td>1781.000</td>\n",
       "      <td>4298.000</td>\n",
       "      <td>394.000</td>\n",
       "      <td>57.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Population  Violent\\ncrime  Murder and\\nnonnegligent\\nmanslaughter  \\\n",
       "count     344.000         344.000                                 344.000   \n",
       "mean    14152.573          33.078                                   0.334   \n",
       "std     18876.821         105.876                                   1.560   \n",
       "min       526.000           0.000                                   0.000   \n",
       "25%      2983.250           2.000                                   0.000   \n",
       "50%      7106.000           6.000                                   0.000   \n",
       "75%     17889.250          21.000                                   0.000   \n",
       "max    143834.000        1192.000                                  21.000   \n",
       "\n",
       "       Rape\\n(revised\\ndefinition)1  Rape\\n(legacy\\ndefinition)2  Robbery  \\\n",
       "count                         0.000                      344.000  344.000   \n",
       "mean                            nan                        1.939   10.378   \n",
       "std                             nan                        5.662   36.304   \n",
       "min                             nan                        0.000    0.000   \n",
       "25%                             nan                        0.000    0.000   \n",
       "50%                             nan                        0.000    1.000   \n",
       "75%                             nan                        2.000    5.000   \n",
       "max                             nan                       75.000  400.000   \n",
       "\n",
       "       Aggravated\\nassault  Property\\ncrime  Burglary  Larceny-\\ntheft  \\\n",
       "count              344.000          344.000   344.000          344.000   \n",
       "mean                20.427          316.703    53.863          253.366   \n",
       "std                 64.049          602.881   134.721          454.847   \n",
       "min                  0.000            0.000     0.000            0.000   \n",
       "25%                  1.000           39.000     6.000           31.000   \n",
       "50%                  4.000          111.500    17.000           93.500   \n",
       "75%                 13.250          334.750    50.000          275.500   \n",
       "max                696.000         6473.000  1781.000         4298.000   \n",
       "\n",
       "       Motor\\nvehicle\\ntheft  Arson3  \n",
       "count                344.000 185.000  \n",
       "mean                   9.474   1.124  \n",
       "std                   28.851   4.758  \n",
       "min                    0.000   0.000  \n",
       "25%                    0.000   0.000  \n",
       "50%                    2.000   0.000  \n",
       "75%                    7.000   1.000  \n",
       "max                  394.000  57.000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a new column from `Robbery` that has binary data based on condition:\n",
    "#df2['Robbery2'] = np.where(df2['Robbery']>5, 1, 0)\n",
    "\n",
    "# Check to make sure it worked.\n",
    "#print(df2['Robbery'].groupby(df2['Robbery2']).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[df['Murder and\\nnonnegligent\\nmanslaughter']>0,'Murder']=1\n",
    "df2.loc[df['Murder and\\nnonnegligent\\nmanslaughter']==0,'Murder']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['City', 'Population', 'Violent\\ncrime',\n",
       "       'Murder and\\nnonnegligent\\nmanslaughter',\n",
       "       'Rape\\n(revised\\ndefinition)1', 'Rape\\n(legacy\\ndefinition)2',\n",
       "       'Robbery', 'Aggravated\\nassault', 'Property\\ncrime', 'Burglary',\n",
       "       'Larceny-\\ntheft', 'Motor\\nvehicle\\ntheft', 'Arson3', 'Murder'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2.drop(['City',\n",
    "       'Murder and\\nnonnegligent\\nmanslaughter',\n",
    "       'Rape\\n(revised\\ndefinition)1'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Population                       int64\n",
       "Violent\\ncrime                   int64\n",
       "Rape\\n(legacy\\ndefinition)2      int64\n",
       "Robbery                          int64\n",
       "Aggravated\\nassault              int64\n",
       "Property\\ncrime                  int64\n",
       "Burglary                         int64\n",
       "Larceny-\\ntheft                  int64\n",
       "Motor\\nvehicle\\ntheft            int64\n",
       "Arson3                         float64\n",
       "Murder                         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill 'na' with zeros:\n",
    "df2['Arson3']=df2['Arson3'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Population</th>\n",
       "      <th>Violent\n",
       "crime</th>\n",
       "      <th>Rape\n",
       "(legacy\n",
       "definition)2</th>\n",
       "      <th>Robbery</th>\n",
       "      <th>Aggravated\n",
       "assault</th>\n",
       "      <th>Property\n",
       "crime</th>\n",
       "      <th>Burglary</th>\n",
       "      <th>Larceny-\n",
       "theft</th>\n",
       "      <th>Motor\n",
       "vehicle\n",
       "theft</th>\n",
       "      <th>Arson3</th>\n",
       "      <th>Murder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143834</td>\n",
       "      <td>1192</td>\n",
       "      <td>75</td>\n",
       "      <td>400</td>\n",
       "      <td>696</td>\n",
       "      <td>6473</td>\n",
       "      <td>1781</td>\n",
       "      <td>4298</td>\n",
       "      <td>394</td>\n",
       "      <td>57.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118296</td>\n",
       "      <td>107</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>68</td>\n",
       "      <td>2118</td>\n",
       "      <td>204</td>\n",
       "      <td>1882</td>\n",
       "      <td>32</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97956</td>\n",
       "      <td>791</td>\n",
       "      <td>30</td>\n",
       "      <td>227</td>\n",
       "      <td>526</td>\n",
       "      <td>4090</td>\n",
       "      <td>705</td>\n",
       "      <td>3243</td>\n",
       "      <td>142</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96667</td>\n",
       "      <td>151</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "      <td>82</td>\n",
       "      <td>2303</td>\n",
       "      <td>332</td>\n",
       "      <td>1925</td>\n",
       "      <td>46</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87204</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "      <td>567</td>\n",
       "      <td>88</td>\n",
       "      <td>466</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>80705</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "      <td>1515</td>\n",
       "      <td>99</td>\n",
       "      <td>1388</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>78800</td>\n",
       "      <td>175</td>\n",
       "      <td>5</td>\n",
       "      <td>81</td>\n",
       "      <td>89</td>\n",
       "      <td>1391</td>\n",
       "      <td>150</td>\n",
       "      <td>1172</td>\n",
       "      <td>69</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>78361</td>\n",
       "      <td>158</td>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "      <td>99</td>\n",
       "      <td>2689</td>\n",
       "      <td>345</td>\n",
       "      <td>2271</td>\n",
       "      <td>73</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>78215</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>1990</td>\n",
       "      <td>186</td>\n",
       "      <td>1753</td>\n",
       "      <td>51</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>68071</td>\n",
       "      <td>554</td>\n",
       "      <td>7</td>\n",
       "      <td>228</td>\n",
       "      <td>317</td>\n",
       "      <td>1436</td>\n",
       "      <td>317</td>\n",
       "      <td>972</td>\n",
       "      <td>147</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>66041</td>\n",
       "      <td>607</td>\n",
       "      <td>31</td>\n",
       "      <td>203</td>\n",
       "      <td>365</td>\n",
       "      <td>2800</td>\n",
       "      <td>769</td>\n",
       "      <td>1878</td>\n",
       "      <td>153</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>61686</td>\n",
       "      <td>361</td>\n",
       "      <td>27</td>\n",
       "      <td>102</td>\n",
       "      <td>225</td>\n",
       "      <td>2528</td>\n",
       "      <td>449</td>\n",
       "      <td>1997</td>\n",
       "      <td>82</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>58082</td>\n",
       "      <td>118</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>86</td>\n",
       "      <td>1099</td>\n",
       "      <td>190</td>\n",
       "      <td>882</td>\n",
       "      <td>27</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>57559</td>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>46</td>\n",
       "      <td>1232</td>\n",
       "      <td>77</td>\n",
       "      <td>1134</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>55198</td>\n",
       "      <td>433</td>\n",
       "      <td>3</td>\n",
       "      <td>204</td>\n",
       "      <td>216</td>\n",
       "      <td>958</td>\n",
       "      <td>206</td>\n",
       "      <td>630</td>\n",
       "      <td>122</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>51506</td>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>1353</td>\n",
       "      <td>271</td>\n",
       "      <td>1049</td>\n",
       "      <td>33</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50603</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>1020</td>\n",
       "      <td>219</td>\n",
       "      <td>752</td>\n",
       "      <td>49</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>49898</td>\n",
       "      <td>371</td>\n",
       "      <td>14</td>\n",
       "      <td>145</td>\n",
       "      <td>211</td>\n",
       "      <td>1985</td>\n",
       "      <td>593</td>\n",
       "      <td>1305</td>\n",
       "      <td>87</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>49574</td>\n",
       "      <td>584</td>\n",
       "      <td>12</td>\n",
       "      <td>166</td>\n",
       "      <td>403</td>\n",
       "      <td>2807</td>\n",
       "      <td>746</td>\n",
       "      <td>1949</td>\n",
       "      <td>112</td>\n",
       "      <td>22.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>46304</td>\n",
       "      <td>284</td>\n",
       "      <td>19</td>\n",
       "      <td>101</td>\n",
       "      <td>161</td>\n",
       "      <td>2349</td>\n",
       "      <td>525</td>\n",
       "      <td>1767</td>\n",
       "      <td>57</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>45535</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>1167</td>\n",
       "      <td>134</td>\n",
       "      <td>1012</td>\n",
       "      <td>21</td>\n",
       "      <td>6.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>44821</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>896</td>\n",
       "      <td>166</td>\n",
       "      <td>710</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>44787</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>578</td>\n",
       "      <td>55</td>\n",
       "      <td>501</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>43866</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>1339</td>\n",
       "      <td>125</td>\n",
       "      <td>1203</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>43777</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>469</td>\n",
       "      <td>101</td>\n",
       "      <td>361</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>43214</td>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "      <td>74</td>\n",
       "      <td>933</td>\n",
       "      <td>168</td>\n",
       "      <td>698</td>\n",
       "      <td>67</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>37438</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>317</td>\n",
       "      <td>41</td>\n",
       "      <td>262</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>37196</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>45</td>\n",
       "      <td>340</td>\n",
       "      <td>83</td>\n",
       "      <td>244</td>\n",
       "      <td>13</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>36689</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>793</td>\n",
       "      <td>142</td>\n",
       "      <td>623</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>36643</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>334</td>\n",
       "      <td>45</td>\n",
       "      <td>287</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>1691</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>1688</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>1628</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>1622</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>1602</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>1553</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>1437</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>1433</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>1428</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>1410</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>1385</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>1351</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>1350</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>1274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1263</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>1097</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>1022</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>980</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>977</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>872</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>829</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>762</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>658</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>656</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>615</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>526</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Population  Violent\\ncrime  Rape\\n(legacy\\ndefinition)2  Robbery  \\\n",
       "0        143834            1192                           75      400   \n",
       "1        118296             107                            7       31   \n",
       "2         97956             791                           30      227   \n",
       "3         96667             151                            9       60   \n",
       "4         87204              57                            5        9   \n",
       "5         80705              65                            8       17   \n",
       "6         78800             175                            5       81   \n",
       "7         78361             158                           11       48   \n",
       "8         78215              63                            0       31   \n",
       "9         68071             554                            7      228   \n",
       "10        66041             607                           31      203   \n",
       "11        61686             361                           27      102   \n",
       "12        58082             118                            5       26   \n",
       "13        57559              78                            3       28   \n",
       "14        55198             433                            3      204   \n",
       "15        51506              93                            6       51   \n",
       "16        50603              44                            6       16   \n",
       "17        49898             371                           14      145   \n",
       "18        49574             584                           12      166   \n",
       "19        46304             284                           19      101   \n",
       "20        45535              38                            1       12   \n",
       "21        44821              35                            1        9   \n",
       "22        44787              48                            5       16   \n",
       "23        43866              39                            1       12   \n",
       "24        43777              21                            2        3   \n",
       "25        43214             152                            2       76   \n",
       "26        37438              37                            1       13   \n",
       "27        37196              64                            3       16   \n",
       "28        36689              26                            2       10   \n",
       "29        36643              15                            0        2   \n",
       "..          ...             ...                          ...      ...   \n",
       "314        1691               3                            0        0   \n",
       "315        1688               0                            0        0   \n",
       "316        1628               0                            0        0   \n",
       "317        1622               0                            0        0   \n",
       "318        1602               0                            0        0   \n",
       "319        1553               0                            0        0   \n",
       "320        1437               0                            0        0   \n",
       "321        1433               2                            0        1   \n",
       "322        1428               1                            0        0   \n",
       "323        1410               0                            0        0   \n",
       "324        1385               0                            0        0   \n",
       "325        1351               1                            0        0   \n",
       "326        1350               1                            0        0   \n",
       "327        1274               0                            0        0   \n",
       "328        1263               3                            0        0   \n",
       "329        1174               0                            0        0   \n",
       "330        1122               0                            0        0   \n",
       "331        1104               0                            0        0   \n",
       "332        1097               0                            0        0   \n",
       "333        1022               1                            0        0   \n",
       "334         997               0                            0        0   \n",
       "335         980               0                            0        0   \n",
       "336         977               0                            0        0   \n",
       "337         872               0                            0        0   \n",
       "338         829               7                            0        0   \n",
       "339         762               0                            0        0   \n",
       "340         658               0                            0        0   \n",
       "341         656               0                            0        0   \n",
       "342         615               0                            0        0   \n",
       "343         526               0                            0        0   \n",
       "\n",
       "     Aggravated\\nassault  Property\\ncrime  Burglary  Larceny-\\ntheft  \\\n",
       "0                    696             6473      1781             4298   \n",
       "1                     68             2118       204             1882   \n",
       "2                    526             4090       705             3243   \n",
       "3                     82             2303       332             1925   \n",
       "4                     41              567        88              466   \n",
       "5                     40             1515        99             1388   \n",
       "6                     89             1391       150             1172   \n",
       "7                     99             2689       345             2271   \n",
       "8                     32             1990       186             1753   \n",
       "9                    317             1436       317              972   \n",
       "10                   365             2800       769             1878   \n",
       "11                   225             2528       449             1997   \n",
       "12                    86             1099       190              882   \n",
       "13                    46             1232        77             1134   \n",
       "14                   216              958       206              630   \n",
       "15                    35             1353       271             1049   \n",
       "16                    22             1020       219              752   \n",
       "17                   211             1985       593             1305   \n",
       "18                   403             2807       746             1949   \n",
       "19                   161             2349       525             1767   \n",
       "20                    24             1167       134             1012   \n",
       "21                    24              896       166              710   \n",
       "22                    26              578        55              501   \n",
       "23                    25             1339       125             1203   \n",
       "24                    16              469       101              361   \n",
       "25                    74              933       168              698   \n",
       "26                    23              317        41              262   \n",
       "27                    45              340        83              244   \n",
       "28                    13              793       142              623   \n",
       "29                    13              334        45              287   \n",
       "..                   ...              ...       ...              ...   \n",
       "314                    3               47         8               39   \n",
       "315                    0                0         0                0   \n",
       "316                    0               14         6                8   \n",
       "317                    0                0         0                0   \n",
       "318                    0               31         0               31   \n",
       "319                    0                1         1                0   \n",
       "320                    0                0         0                0   \n",
       "321                    1               13         1               12   \n",
       "322                    1               12         0               11   \n",
       "323                    0               14         2               12   \n",
       "324                    0               10         2                8   \n",
       "325                    1               15         7                8   \n",
       "326                    1                2         0                2   \n",
       "327                    0                0         0                0   \n",
       "328                    3               15         0               15   \n",
       "329                    0               10         0               10   \n",
       "330                    0                8         2                6   \n",
       "331                    0               66         4               60   \n",
       "332                    0                1         0                1   \n",
       "333                    1                4         2                2   \n",
       "334                    0                8         1                7   \n",
       "335                    0                4         0                4   \n",
       "336                    0               41        13               27   \n",
       "337                    0                0         0                0   \n",
       "338                    7               17         8                9   \n",
       "339                    0                2         0                2   \n",
       "340                    0                2         0                2   \n",
       "341                    0               10         1                9   \n",
       "342                    0                0         0                0   \n",
       "343                    0                5         0                5   \n",
       "\n",
       "     Motor\\nvehicle\\ntheft  Arson3  Murder  \n",
       "0                      394  57.000   1.000  \n",
       "1                       32   3.000   1.000  \n",
       "2                      142   0.000   1.000  \n",
       "3                       46   0.000   0.000  \n",
       "4                       13   0.000   1.000  \n",
       "5                       28   0.000   0.000  \n",
       "6                       69   0.000   0.000  \n",
       "7                       73   2.000   0.000  \n",
       "8                       51  10.000   0.000  \n",
       "9                      147   0.000   1.000  \n",
       "10                     153   0.000   1.000  \n",
       "11                      82   0.000   1.000  \n",
       "12                      27   1.000   1.000  \n",
       "13                      21   0.000   1.000  \n",
       "14                     122   2.000   1.000  \n",
       "15                      33   0.000   1.000  \n",
       "16                      49   1.000   0.000  \n",
       "17                      87   5.000   1.000  \n",
       "18                     112  22.000   1.000  \n",
       "19                      57   0.000   1.000  \n",
       "20                      21   6.000   1.000  \n",
       "21                      20   0.000   1.000  \n",
       "22                      22   0.000   1.000  \n",
       "23                      11   0.000   1.000  \n",
       "24                       7   0.000   0.000  \n",
       "25                      67   8.000   0.000  \n",
       "26                      14   0.000   0.000  \n",
       "27                      13   3.000   0.000  \n",
       "28                      28   0.000   1.000  \n",
       "29                       2   0.000   0.000  \n",
       "..                     ...     ...     ...  \n",
       "314                      0   0.000   0.000  \n",
       "315                      0   0.000   0.000  \n",
       "316                      0   0.000   0.000  \n",
       "317                      0   0.000   0.000  \n",
       "318                      0   0.000   0.000  \n",
       "319                      0   0.000   0.000  \n",
       "320                      0   0.000   0.000  \n",
       "321                      0   0.000   0.000  \n",
       "322                      1   1.000   0.000  \n",
       "323                      0   0.000   0.000  \n",
       "324                      0   0.000   0.000  \n",
       "325                      0   0.000   0.000  \n",
       "326                      0   0.000   0.000  \n",
       "327                      0   0.000   0.000  \n",
       "328                      0   0.000   0.000  \n",
       "329                      0   0.000   0.000  \n",
       "330                      0   0.000   0.000  \n",
       "331                      2   0.000   0.000  \n",
       "332                      0   0.000   0.000  \n",
       "333                      0   0.000   0.000  \n",
       "334                      0   0.000   0.000  \n",
       "335                      0   0.000   0.000  \n",
       "336                      1   0.000   0.000  \n",
       "337                      0   0.000   0.000  \n",
       "338                      0   0.000   0.000  \n",
       "339                      0   0.000   0.000  \n",
       "340                      0   0.000   0.000  \n",
       "341                      0   0.000   0.000  \n",
       "342                      0   0.000   0.000  \n",
       "343                      0   0.000   0.000  \n",
       "\n",
       "[344 rows x 11 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning the initial data frame I create a new one that will be used as the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "murder_base = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We would like to predict if the city will be classified as a murder one or safe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "murder_df = df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are a few big outliers !\n",
    "We need feature transformation: drop outliers, apply log, cube etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1df48c26240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(murder_df['Population'],bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Population</th>\n",
       "      <th>Violent\n",
       "crime</th>\n",
       "      <th>Rape\n",
       "(legacy\n",
       "definition)2</th>\n",
       "      <th>Robbery</th>\n",
       "      <th>Aggravated\n",
       "assault</th>\n",
       "      <th>Property\n",
       "crime</th>\n",
       "      <th>Burglary</th>\n",
       "      <th>Larceny-\n",
       "theft</th>\n",
       "      <th>Motor\n",
       "vehicle\n",
       "theft</th>\n",
       "      <th>Arson3</th>\n",
       "      <th>Murder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>143834</td>\n",
       "      <td>1192</td>\n",
       "      <td>75</td>\n",
       "      <td>400</td>\n",
       "      <td>696</td>\n",
       "      <td>6473</td>\n",
       "      <td>1781</td>\n",
       "      <td>4298</td>\n",
       "      <td>394</td>\n",
       "      <td>57.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>118296</td>\n",
       "      <td>107</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>68</td>\n",
       "      <td>2118</td>\n",
       "      <td>204</td>\n",
       "      <td>1882</td>\n",
       "      <td>32</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97956</td>\n",
       "      <td>791</td>\n",
       "      <td>30</td>\n",
       "      <td>227</td>\n",
       "      <td>526</td>\n",
       "      <td>4090</td>\n",
       "      <td>705</td>\n",
       "      <td>3243</td>\n",
       "      <td>142</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>96667</td>\n",
       "      <td>151</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "      <td>82</td>\n",
       "      <td>2303</td>\n",
       "      <td>332</td>\n",
       "      <td>1925</td>\n",
       "      <td>46</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>87204</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "      <td>567</td>\n",
       "      <td>88</td>\n",
       "      <td>466</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Population  Violent\\ncrime  Rape\\n(legacy\\ndefinition)2  Robbery  \\\n",
       "310      143834            1192                           75      400   \n",
       "7        118296             107                            7       31   \n",
       "3         97956             791                           30      227   \n",
       "126       96667             151                            9       60   \n",
       "267       87204              57                            5        9   \n",
       "\n",
       "     Aggravated\\nassault  Property\\ncrime  Burglary  Larceny-\\ntheft  \\\n",
       "310                  696             6473      1781             4298   \n",
       "7                     68             2118       204             1882   \n",
       "3                    526             4090       705             3243   \n",
       "126                   82             2303       332             1925   \n",
       "267                   41              567        88              466   \n",
       "\n",
       "     Motor\\nvehicle\\ntheft  Arson3  Murder  \n",
       "310                    394  57.000   1.000  \n",
       "7                       32   3.000   1.000  \n",
       "3                      142   0.000   1.000  \n",
       "126                     46   0.000   0.000  \n",
       "267                     13   0.000   1.000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Who are the biggest towns ?\n",
    "murder_df.sort_values('Population', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1df48cb0748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.distplot( murder_df[\"Population\"] , color=\"red\", label=\"Population\",bins=6)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reset index b/c some rows are missing after processing the dataframe and 'concatenate' will not be done properly!\n",
    "murder_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize each column:\n",
    "from sklearn import preprocessing\n",
    "\n",
    "names = murder_df.drop(['Murder'],axis=1).columns\n",
    "# murder_df_scaled = pd.DataFrame(preprocessing.scale(murder_df.drop(['Murder'],axis=1)), columns=names)\n",
    "murder_df_scaled = pd.DataFrame(preprocessing.scale(murder_df.loc[:, ~(murder_df.columns).isin(['Murder'])]), columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Population</th>\n",
       "      <th>Violent\n",
       "crime</th>\n",
       "      <th>Rape\n",
       "(legacy\n",
       "definition)2</th>\n",
       "      <th>Robbery</th>\n",
       "      <th>Aggravated\n",
       "assault</th>\n",
       "      <th>Property\n",
       "crime</th>\n",
       "      <th>Burglary</th>\n",
       "      <th>Larceny-\n",
       "theft</th>\n",
       "      <th>Motor\n",
       "vehicle\n",
       "theft</th>\n",
       "      <th>Arson3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.880</td>\n",
       "      <td>10.962</td>\n",
       "      <td>12.922</td>\n",
       "      <td>10.748</td>\n",
       "      <td>10.563</td>\n",
       "      <td>10.226</td>\n",
       "      <td>12.839</td>\n",
       "      <td>8.905</td>\n",
       "      <td>13.348</td>\n",
       "      <td>15.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.525</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.744</td>\n",
       "      <td>2.992</td>\n",
       "      <td>1.116</td>\n",
       "      <td>3.586</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.446</td>\n",
       "      <td>7.169</td>\n",
       "      <td>4.963</td>\n",
       "      <td>5.976</td>\n",
       "      <td>7.905</td>\n",
       "      <td>6.268</td>\n",
       "      <td>4.840</td>\n",
       "      <td>6.582</td>\n",
       "      <td>4.600</td>\n",
       "      <td>-0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.378</td>\n",
       "      <td>1.115</td>\n",
       "      <td>1.249</td>\n",
       "      <td>1.369</td>\n",
       "      <td>0.963</td>\n",
       "      <td>3.299</td>\n",
       "      <td>2.068</td>\n",
       "      <td>3.681</td>\n",
       "      <td>1.268</td>\n",
       "      <td>-0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.876</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.541</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Population  Violent\\ncrime  Rape\\n(legacy\\ndefinition)2  Robbery  \\\n",
       "0       6.880          10.962                       12.922   10.748   \n",
       "1       5.525           0.699                        0.895    0.569   \n",
       "2       4.446           7.169                        4.963    5.976   \n",
       "3       4.378           1.115                        1.249    1.369   \n",
       "4       3.876           0.226                        0.541   -0.038   \n",
       "\n",
       "   Aggravated\\nassault  Property\\ncrime  Burglary  Larceny-\\ntheft  \\\n",
       "0               10.563           10.226    12.839            8.905   \n",
       "1                0.744            2.992     1.116            3.586   \n",
       "2                7.905            6.268     4.840            6.582   \n",
       "3                0.963            3.299     2.068            3.681   \n",
       "4                0.322            0.416     0.254            0.468   \n",
       "\n",
       "   Motor\\nvehicle\\ntheft  Arson3  \n",
       "0                 13.348  15.999  \n",
       "1                  0.782   0.680  \n",
       "2                  4.600  -0.172  \n",
       "3                  1.268  -0.172  \n",
       "4                  0.122  -0.172  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "murder_df_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the scaled dataframe with the target column 'Murder':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "murder_df_scaled = pd.concat((murder_df_scaled , murder_df['Murder']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Population</th>\n",
       "      <th>Violent\n",
       "crime</th>\n",
       "      <th>Rape\n",
       "(legacy\n",
       "definition)2</th>\n",
       "      <th>Robbery</th>\n",
       "      <th>Aggravated\n",
       "assault</th>\n",
       "      <th>Property\n",
       "crime</th>\n",
       "      <th>Burglary</th>\n",
       "      <th>Larceny-\n",
       "theft</th>\n",
       "      <th>Motor\n",
       "vehicle\n",
       "theft</th>\n",
       "      <th>Arson3</th>\n",
       "      <th>Murder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Population, Violent\n",
       "crime, Rape\n",
       "(legacy\n",
       "definition)2, Robbery, Aggravated\n",
       "assault, Property\n",
       "crime, Burglary, Larceny-\n",
       "theft, Motor\n",
       "vehicle\n",
       "theft, Arson3, Murder]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# murder_df['Murder'].sort_index().head(37)\n",
    "\n",
    "# Are there any 'nan' left?\n",
    "murder_df[murder_df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a binary logistic model using SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a logistic regression classifier.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_simple = LogisticRegression(  ) # C = 1e100 = I'm using this C to compensate for the default penalty parameter ='L2'!\n",
    "lr1_lasso = LogisticRegression( penalty='l1' )\n",
    "lr2_ridge = LogisticRegression( penalty='l2' )\n",
    "\n",
    "y = murder_df_scaled['Murder']\n",
    "X = murder_df_scaled.drop(['Murder'] , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000000.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275, 10) (275,)\n",
      "(69, 10) (69,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
    "\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model.\n",
    "lr_simple.fit( X_train, y_train )\n",
    "# I'm using this C to compensate for the default penalty parameter ='L2'!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients\n",
      "[[ 0.46  0.6   0.65  0.01  0.53  0.01  0.92 -0.21 -0.72  0.47]]\n",
      "[-2.]\n"
     ]
    }
   ],
   "source": [
    "# Display Coefficients:\n",
    "print('Coefficients')\n",
    "print(lr_simple.coef_)\n",
    "print(lr_simple.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0.])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the test set results:\n",
    "pred_y_sklearn = lr_simple.predict( X_test )\n",
    "pred_y_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual  Predicted\n",
       "63    1.000      0.000\n",
       "177   0.000      0.000\n",
       "121   0.000      0.000\n",
       "47    0.000      0.000\n",
       "210   0.000      0.000\n",
       "226   0.000      0.000\n",
       "267   0.000      0.000\n",
       "232   0.000      0.000\n",
       "196   0.000      0.000\n",
       "13    1.000      0.000\n",
       "221   0.000      0.000\n",
       "256   0.000      0.000\n",
       "182   0.000      0.000\n",
       "204   0.000      0.000\n",
       "104   0.000      0.000\n",
       "257   0.000      0.000\n",
       "83    0.000      0.000\n",
       "298   0.000      0.000\n",
       "200   0.000      0.000\n",
       "117   0.000      0.000\n",
       "94    0.000      0.000\n",
       "279   0.000      0.000\n",
       "115   0.000      0.000\n",
       "199   0.000      0.000\n",
       "290   0.000      0.000\n",
       "222   0.000      0.000\n",
       "89    0.000      0.000\n",
       "189   0.000      0.000\n",
       "14    1.000      1.000\n",
       "61    0.000      0.000\n",
       "..      ...        ...\n",
       "28    1.000      0.000\n",
       "129   0.000      0.000\n",
       "119   0.000      0.000\n",
       "306   0.000      0.000\n",
       "110   0.000      0.000\n",
       "56    0.000      0.000\n",
       "329   0.000      0.000\n",
       "120   0.000      0.000\n",
       "316   0.000      0.000\n",
       "301   0.000      0.000\n",
       "163   1.000      0.000\n",
       "320   0.000      0.000\n",
       "148   0.000      0.000\n",
       "245   0.000      0.000\n",
       "0     1.000      1.000\n",
       "81    0.000      0.000\n",
       "335   0.000      0.000\n",
       "216   0.000      0.000\n",
       "284   0.000      0.000\n",
       "102   0.000      0.000\n",
       "302   0.000      0.000\n",
       "156   0.000      0.000\n",
       "249   0.000      0.000\n",
       "260   0.000      0.000\n",
       "333   0.000      0.000\n",
       "212   0.000      0.000\n",
       "211   0.000      0.000\n",
       "165   0.000      0.000\n",
       "53    0.000      0.000\n",
       "311   0.000      0.000\n",
       "\n",
       "[69 rows x 2 columns]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare some of our predicted values with the actual values and see how accurate we were:\n",
    "df_compare=pd.DataFrame({'Actual':y_test, 'Predicted':pred_y_sklearn})  \n",
    "df_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy by admission status(Confusion matrix):\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0.0         61    1   62\n",
      "1.0          5    2    7\n",
      "All         66    3   69\n",
      "\n",
      "Accuracy of logistic regression classifier on test set: 0.91\n"
     ]
    }
   ],
   "source": [
    "print('\\n Accuracy by admission status(Confusion matrix):\\n')\n",
    "print(pd.crosstab( y_test , pred_y_sklearn , rownames=['Actual'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "print('\\nAccuracy of logistic regression classifier on test set: {:.2f}'.format(lr_simple.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus in binary classification C_{i,j}, the count of \n",
    "- true negatives is C_{0,0}  --> (it was predicted 0 (j) and discovered to be 0 (i)), \n",
    "- false negatives is C_{1,0} --> (it was predicted 0 (j) and discovered to be 1 (i)),\n",
    "- true positives is C_{1,1}  --> (it was predicted 1 (j) and discovered to be 1 (i)), \n",
    "- false positives is C_{0,1} --> (it was predicted 1 (j) and discovered to be 0 (i)),\n",
    "    \n",
    "    \n",
    "      |0   1| <--predicted\n",
    "    0 |tn fp|\n",
    "    1 |fn tp|\n",
    "    ^\n",
    "    |\n",
    "    actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy by admission status(Confusion matrix)\n",
      "[[61  1]\n",
      " [ 5  2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('\\n Accuracy by admission status(Confusion matrix)')\n",
    "confusion_matrix = confusion_matrix(y_test, pred_y_sklearn)\n",
    "print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, the results are different, why?\n",
    "#import pandas as pd\n",
    "#y_true = pd.Series(y_test)\n",
    "#y_pred = pd.Series(pred_y_sklearn)\n",
    "#\n",
    "#pd.crosstab(y_true, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the test set results and calculating the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.91\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(lr_simple.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "\n",
    "Cross validation attempts to avoid overfitting while still producing a prediction for each observation dataset. We are using 10-fold Cross-Validation to train our Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86 0.89 0.96 0.86 0.79 0.93 0.93 0.85 0.85 0.93]\n",
      "10-fold cross validation average accuracy: 0.884\n",
      "\n",
      "--- 0.03125452995300293 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "scoring = 'accuracy'\n",
    "\n",
    "results = cross_val_score( lr_simple , X_train, y_train , cv=kfold)\n",
    "print(results)\n",
    "\n",
    "print(\"10-fold cross validation average accuracy: %.3f\" % (results.mean()))\n",
    "\n",
    "print(\"\\n--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](cross_validation_graph.png)\n",
    "In K-Folds Cross Validation we split our data into k different subsets (or folds). We use k-1 subsets to train our data and leave the last subset (or the last fold) as test data. We then average the model against each of the folds and then finalize our model. After that we test it against the test set.\n",
    "\n",
    "![title](kfold_cross_validation.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute precision, recall, F-measure and support\n",
    "\n",
    "The precision is the ratio \n",
    "      tp \n",
    "    ---------\n",
    "    (tp + fp) \n",
    "where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier to not label a sample as positive if it is negative.\n",
    "\n",
    "The recall is the ratio \n",
    "      tp \n",
    "    ---------\n",
    "    (tp + fn) \n",
    "where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "\n",
    "The F-beta score can be interpreted as a weighted harmonic mean of the precision and recall, where an F-beta score reaches its best value at 1 and worst score at 0.\n",
    "\n",
    "The F-beta score weights the recall more than the precision by a factor of beta. beta = 1.0 means recall and precision are equally important.\n",
    "\n",
    "The support is the number of occurrences of each class in y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.98      0.95        62\n",
      "        1.0       0.67      0.29      0.40         7\n",
      "\n",
      "avg / total       0.90      0.91      0.90        69\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred_y_sklearn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning:\n",
    "\n",
    "While model parameters are learned during training — such as the slope and intercept in a linear regression — hyperparameters must be set by the data scientist before training.\n",
    "\n",
    "Hyperparameter tuning relies more on experimental results than theory, and thus the best method to determine the optimal settings is to try many different combinations evaluate the performance of each model. \n",
    "\n",
    "However, evaluating each model only on the training set can lead to one of the most fundamental problems in machine learning: <b>overfitting<b/>.\n",
    "    \n",
    "     the standard procedure for hyperparameter optimization accounts for overfitting through cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'C': 1.0,\n",
      " 'class_weight': None,\n",
      " 'dual': False,\n",
      " 'fit_intercept': True,\n",
      " 'intercept_scaling': 1,\n",
      " 'max_iter': 100,\n",
      " 'multi_class': 'ovr',\n",
      " 'n_jobs': 1,\n",
      " 'penalty': 'l2',\n",
      " 'random_state': None,\n",
      " 'solver': 'liblinear',\n",
      " 'tol': 0.0001,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(lr_simple.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the best hyperparameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1', 'C': 1000.0}\n",
      "\n",
      "--- 2.953199863433838 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "param_grid = {\n",
    "               'C': [0.1, 0.5, 1, 5, 10, 50, 100,1e3,1e5,1e10]   \n",
    "                # Create regularization penalty space\n",
    "                ,'penalty': ['l1', 'l2']\n",
    "              }\n",
    "\n",
    "param_clasf = GridSearchCV( lr_simple\n",
    "                           , param_grid\n",
    "                           , cv=5,\n",
    "                       scoring='accuracy')\n",
    "param_clasf.fit(X_train, y_train)\n",
    "print(param_clasf.best_params_)\n",
    "\n",
    "\n",
    "print(\"\\n--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the written code is big and not easy to follow I made o copy of this notebook and ran the logistic classifier with the specified parameters.\n",
    "I discovered that the results were perfect, the model predicted everything. The results were the same as the first run of the logistic model that have C=1e10 and default penalty (l2).\n",
    "\n",
    "I also discovered that if I run the GridSearchCV a couple more times, the penalty changes from l1 to l2 but 'C' remains 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction: SelectKbest\n",
    "\n",
    "SelectKBest selects the top $k$ features that have maximum relevance with the target variable (they explain most of the variance). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "# from sklearn.feature_selection import f_regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f_classif: ANOVA F-value between label/feature for classification tasks.\n",
    "\n",
    "chi2 : is also good for classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=5, score_func=<function f_classif at 0x000001DF489AA9D8>)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature extraction\n",
    "lr_kbest = SelectKBest(score_func=f_classif, k=5)\n",
    "\n",
    "#Fitting finds the internal parameters of a model that will be used to transform data. \n",
    "# To center the data (make it have zero mean and unit standard error)\n",
    "# , you subtract the mean and then divide the result by the standard deviation.\n",
    "fitted = lr_kbest.fit(X_train, y_train)\n",
    "fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 examples:  [[-0.1  -0.17 -0.18 -0.08 -0.18]\n",
      " [-0.28 -0.34 -0.29 -0.37 -0.31]]\n",
      "number of examples: 69\n"
     ]
    }
   ],
   "source": [
    "#Transforming applies the parameters to data. You may fit a model to one set of data, and then \n",
    "#transform it on a completely different set.\n",
    "features = fitted.transform(X_test)\n",
    "print('2 examples: ',features[:2])\n",
    "print('number of examples:',len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 82.24 104.52 112.66  96.93  97.71 104.8  116.69  94.44  83.09  22.83]\n"
     ]
    }
   ],
   "source": [
    "# summarize scores\n",
    "np.set_printoptions(precision=2)\n",
    "print(fitted.scores_[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Violent\\ncrime', 'Rape\\n(legacy\\ndefinition)2',\n",
       "       'Aggravated\\nassault', 'Property\\ncrime', 'Burglary'], dtype=object)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_kbest.get_support()\n",
    "np.array(X.columns)[lr_kbest.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var2:\n",
    "#X_train_lr = lr_kbest.fit_transform(X_train, y_train)\n",
    "#X_test_lr = lr_kbest.transform(X_test)\n",
    "#\n",
    "#selected_feature_names = [names[i] for i in lr_kbest.get_support(indices=True)]\n",
    "#selected_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>feature</th>\n",
       "      <th>p_value</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Aggravated\\nassault</td>\n",
       "      <td>0.000</td>\n",
       "      <td>112.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Rape\\n(legacy\\ndefinition)2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>104.517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Burglary</td>\n",
       "      <td>0.000</td>\n",
       "      <td>97.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Property\\ncrime</td>\n",
       "      <td>0.000</td>\n",
       "      <td>96.927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Violent\\ncrime</td>\n",
       "      <td>0.000</td>\n",
       "      <td>82.237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                      feature  p_value   score\n",
       "0      2          Aggravated\\nassault    0.000 112.661\n",
       "1      1  Rape\\n(legacy\\ndefinition)2    0.000 104.517\n",
       "2      4                     Burglary    0.000  97.707\n",
       "3      3              Property\\ncrime    0.000  96.927\n",
       "4      0               Violent\\ncrime    0.000  82.237"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_feature_names = [names[i] for i in lr_kbest.get_support(indices=True)]\n",
    "selected_feature_names\n",
    "\n",
    "feat_names = []\n",
    "feat_scores = []\n",
    "feat_pval = []\n",
    "\n",
    "for n in range(0, len(selected_feature_names)):\n",
    "    #lr_kbest = SelectKBest(score_func=f_classif, k=10)\n",
    "    #fitted = lr_kbest.fit(X_train, y_train)    \n",
    "    #print(\" %s : %.2f\"  % (selected_feature_names[n],fitted.scores_[n]))\n",
    "    \n",
    "    feat_names.append(selected_feature_names[n])\n",
    "    feat_scores.append(fitted.scores_[n])\n",
    "    feat_pval.append(fitted.pvalues_[n])\n",
    "\n",
    "# Create a data frame for a better way of visualization:    \n",
    "feature_scoring = pd.DataFrame({\n",
    "        'feature': feat_names,\n",
    "        'score': feat_scores,\n",
    "        'p_value':feat_pval\n",
    "    })\n",
    "# scores are better if greater, p-values are better if smaller (and losses are better if smaller)\n",
    "feature_scoring.sort_values('score' , ascending = False).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectKBest <u>defaults</u> to scoring parameters using the ANOVA F-value which is a measure of variation between sample means. \n",
    "\n",
    "It describes how much of the variance between labels is explained by a particular feature. A higher value therefore means that there is more variation in that feature between person of interests and non persons of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model with selectKbest features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Violent\n",
       "crime</th>\n",
       "      <th>Rape\n",
       "(legacy\n",
       "definition)2</th>\n",
       "      <th>Aggravated\n",
       "assault</th>\n",
       "      <th>Property\n",
       "crime</th>\n",
       "      <th>Burglary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.266</td>\n",
       "      <td>-0.343</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>-0.207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.171</td>\n",
       "      <td>-0.343</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.180</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.052</td>\n",
       "      <td>-0.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.228</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>-0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.285</td>\n",
       "      <td>-0.343</td>\n",
       "      <td>-0.288</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Violent\\ncrime  Rape\\n(legacy\\ndefinition)2  Aggravated\\nassault  \\\n",
       "0          -0.266                       -0.343               -0.257   \n",
       "1          -0.171                       -0.343               -0.116   \n",
       "2          -0.180                       -0.166               -0.116   \n",
       "3          -0.228                       -0.166               -0.226   \n",
       "4          -0.285                       -0.343               -0.288   \n",
       "\n",
       "   Property\\ncrime  Burglary  \n",
       "0           -0.267    -0.207  \n",
       "1            0.029    -0.066  \n",
       "2            0.052    -0.133  \n",
       "3           -0.196    -0.110  \n",
       "4           -0.068    -0.192  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[feat_names].reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model.\n",
    "lr_simple.fit( X_train[feat_names], y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.91\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(lr_simple.score(X_test[feat_names], y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89 0.93 0.96 0.86 0.75 0.93 0.93 0.85 0.85 0.93]\n",
      "10-fold cross validation average accuracy for SelectKBest: 0.887\n",
      "\n",
      "--- 0.015626907348632812 seconds ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "results_kbest = cross_val_score( lr_simple , X_train[feat_names] , y_train , cv=kfold)\n",
    "print(results_kbest)\n",
    "\n",
    "print(\"10-fold cross validation average accuracy for SelectKBest: %.3f\" % (results_kbest.mean()))\n",
    "\n",
    "print(\"\\n--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is the same as with the whole columns.\n",
    "\n",
    "Cross validation gives also a consistent value across the 10 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try PCA\n",
    "PCA is a complexity-reduction technique that tries to reduce a set of variables down to a smaller set of components that represent most of the information in the variables. At a conceptual level, PCA works by identifying sets of variables that share variance, and creating a component to represent that variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "\n",
    "# Normalize the data so that all variables have a mean of 0 and standard deviation\n",
    "# of 1.\n",
    "X_pca = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of total variance in the dataset explained by each component from Sklearn PCA.\n",
      " [8.42e-01 7.16e-02 4.13e-02 2.24e-02 1.09e-02 6.39e-03 3.44e-03 1.91e-03\n",
      " 2.55e-06 1.53e-33]\n"
     ]
    }
   ],
   "source": [
    "sklearn_pca = PCA(n_components = len(X.columns) )\n",
    "Y_sklearn = sklearn_pca.fit_transform(X_pca)\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "print(\n",
    "    'The percentage of total variance in the dataset explained by each',\n",
    "    'component from Sklearn PCA.\\n',\n",
    "    sklearn_pca.explained_variance_ratio_\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.45e+00, 7.18e-01, 4.14e-01, 2.24e-01, 1.09e-01, 6.41e-02,\n",
       "       3.45e-02, 1.91e-02, 2.56e-05, 1.53e-32])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the numbers of the eigenvalues?\n",
    "pca = PCA()\n",
    "eigenvalues = sklearn_pca.explained_variance_\n",
    "eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon visual inspection, the analyst will keep all the components whose eigenvalue falls above the point where the slope of the line changes the most drastically, also called the \"elbow\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1df4b2ef240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(eigenvalues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model with PCA top 1 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ppal_comp_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ppal_comp_1\n",
       "0       35.686\n",
       "1        5.401\n",
       "2       16.982\n",
       "3        6.059\n",
       "4        1.776"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca_1 = pd.DataFrame(data = Y_sklearn[:,0:1]\n",
    "             , columns = ['ppal_comp_1'])\n",
    "X_pca_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the y_train and reset index before concatenation:\n",
    "y_pca=y.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#principalDf = pd.concat((X_train_pca , y_train_pca),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model.\n",
    "lr_simple.fit( X_pca_1, y_pca )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier with PCA on test set: 0.89\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of logistic regression classifier with PCA on test set: {:.2f}'.format(lr_simple.score(X_pca_1, y_pca)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66 0.69 0.89 0.89 0.91 0.91 1.   1.   1.   1.  ]\n",
      "10-fold cross validation average accuracy for SelectKBest: 0.894\n",
      "\n",
      "--- 0.031243562698364258 seconds ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "results_pca_cv = cross_val_score( lr_simple , X_pca_1 , y_pca , cv=kfold)\n",
    "print(results_pca_cv)\n",
    "\n",
    "print(\"10-fold cross validation average accuracy for SelectKBest: %.3f\" % (results_pca_cv.mean()))\n",
    "\n",
    "print(\"\\n--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With only one feature, the PCA has a higher score than selectKBest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
